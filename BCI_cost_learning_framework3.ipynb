{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sub-band CSTP with data_set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Villa/anaconda/lib/python2.7/site-packages/sklearn/lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/Users/Villa/anaconda/lib/python2.7/site-packages/ipykernel/pylab/config.py:66: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  inline backend.\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Villa/anaconda/lib/python2.7/site-packages/ipykernel/pylab/config.py:71: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  'retina', 'jpeg', 'svg', 'pdf'.\"\"\")\n",
      "/Users/Villa/anaconda/lib/python2.7/site-packages/ipykernel/pylab/config.py:85: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  use `figure_formats` instead)\"\"\")\n",
      "/Users/Villa/anaconda/lib/python2.7/site-packages/ipykernel/pylab/config.py:95: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  \"\"\"\n",
      "/Users/Villa/anaconda/lib/python2.7/site-packages/ipykernel/pylab/config.py:114: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  \"\"\")\n",
      "/Users/Villa/anaconda/lib/python2.7/site-packages/ipykernel/pylab/config.py:44: DeprecationWarning: InlineBackend._config_changed is deprecated: use @observe and @unobserve instead.\n",
      "  def _config_changed(self, name, old, new):\n",
      "/Users/Villa/anaconda/lib/python2.7/site-packages/traitlets/traitlets.py:770: DeprecationWarning: A parent of InlineBackend._config_changed has adopted the new @observe(change) API\n",
      "  clsname, change_or_name), DeprecationWarning)\n",
      "/Users/Villa/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py:43: DeprecationWarning: IPythonKernel._eventloop_changed is deprecated: use @observe and @unobserve instead.\n",
      "  def _eventloop_changed(self, name, old, new):\n",
      "/Users/Villa/anaconda/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['pylab']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import os, glob, sys, platform\n",
    "import pylab\n",
    "import scipy.io\n",
    "from scipy.signal import butter, lfilter, freqs\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics \n",
    "import pdb\n",
    "import mne\n",
    "from mne.decoding import CSP\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "%pylab qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------import data---------------------------------------------\n",
    "def load_epoch(path_data,file_name):\n",
    "    os.chdir(path_data)\n",
    "    data=scipy.io.loadmat(file_name)\n",
    "    keys=data.keys()\n",
    "    for i in range(0,len(keys)):\n",
    "        if keys[i] != '__version__' and keys[i] !='__header__' and keys[i] !='__globals__':\n",
    "            EEG=data[keys[i]]\n",
    "    return EEG\n",
    "\n",
    "# ---------------------------------------common spatial temporal pattern------------------------------------\n",
    "def myCSP(epoch,label):\n",
    "    data=transpose(epoch,(0,2,1))  # obs,chan,time\n",
    "    csp=CSP(n_components=6,reg='oas')\n",
    "    csp.fit(data,label)\n",
    "    cs_pattern=csp.patterns_.T  # columns are common spatial patterns (chan * patterns)\n",
    "    cs_filter=csp.filters_  # patterns * chan\n",
    "    return cs_pattern, cs_filter\n",
    "\n",
    "def myCTP(epoch,label,downsampling):\n",
    "    # resampling\n",
    "    data=epoch[:,0::downsampling,:]\n",
    "    low=float(300)\n",
    "    high=float(500)\n",
    "    ctp=CSP(n_components=6,reg='oas')\n",
    "    ctp.fit(data,label)\n",
    "    ct_pattern=ctp.patterns_.T  # columns are common spatial patterns (time * patterns)\n",
    "    ct_filter=ctp.filters_  # patterns * time\n",
    "    return ct_pattern, ct_filter\n",
    "\n",
    "def signal_projection(filter_para, epoch):\n",
    "    data=transpose(epoch,(0,2,1))   # data: obs,chan,var\n",
    "    signal=reshape(filter_para.dot(data),(shape(epoch)[0],shape(epoch)[1]))\n",
    "    return signal\n",
    "\n",
    "# --------------------------------------------------CSP and CTP comparision--------------------------------\n",
    "def chan_corre(epoch):\n",
    "    obs,vari,chan=shape(epoch)[0], shape(epoch)[1], shape(epoch)[2]\n",
    "    covariance=zeros([chan,chan])\n",
    "    for i in range(0,obs):\n",
    "        covariance=covariance+cov(epoch[i,:,:].T)/trace(cov(epoch[i,:,:].T))\n",
    "    return covariance/obs\n",
    "\n",
    "def max_target_lamba_ind(epoch_target,epoch_standard,cs_pattern,cs_filter):\n",
    "    sig_target=chan_corre(epoch_target)\n",
    "    sig_standard=chan_corre(epoch_standard)\n",
    "    eig_target=diag(cs_filter.dot(sig_target).dot(cs_filter.T))\n",
    "    eig_standard=diag(cs_filter.dot(sig_standard).dot(cs_filter.T))\n",
    "    ind=where(eig_target/eig_standard==max(eig_target/eig_standard))[0]\n",
    "    return ind[0]\n",
    "\n",
    "def CSP_filter_sign(cs_filter_para,target):\n",
    "    cs_target=zeros([1,shape(target)[1]])\n",
    "    for i in range(0,shape(target)[0]):\n",
    "        cs_target=cs_target+cs_filter_para.dot(target[i,:,:].T)\n",
    "    cs_target_mean=cs_target/(i+1)\n",
    "    if sum(cs_target_mean[:,325:450],axis=1)<0:\n",
    "        cs_filter_para=-cs_filter_para\n",
    "    return cs_filter_para\n",
    "\n",
    "def CTP_pattern_sign(ct_pattern_para):\n",
    "    if amax(ct_pattern_para)<0:\n",
    "        ct_pattern_para=-ct_pattern_para\n",
    "    return ct_pattern_para\n",
    "\n",
    "# --------------------------------------------------------filter--------------------------------------------\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='bandpass')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def butter_bandstop(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='bandstop')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandstop_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandstop(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------classification----------------------------------------------\n",
    "def covariance(X):\n",
    "    mu=mean(X,axis=0)\n",
    "    N=shape(X)[0]\n",
    "    S=(X-mu).T.dot(X-mu)/(N-1)\n",
    "    return S\n",
    "\n",
    "# new lda\n",
    "def my_new_lda(X_train,label_train):\n",
    "    x1,x2,label1,label2=sample_arrange(X_train,label_train)\n",
    "    x1_mean=mean(x1,axis=0,keepdims=True)\n",
    "    x2_mean=mean(x2,axis=0,keepdims=True)\n",
    "    s1=zeros([shape(x1)[1],shape(x1)[1]])\n",
    "    s2=zeros([shape(x2)[1],shape(x2)[1]])\n",
    "    \n",
    "    for i in range(0,shape(x1)[0]):\n",
    "        s1=s1+(x1[i:i+1,:]-x1_mean).T.dot(x1[i:i+1,:]-x1_mean)\n",
    "        \n",
    "    for i in range(0,shape(x2)[0]):\n",
    "        s2=s2+(x2[i:i+1,:]-x2_mean).T.dot(x2[i:i+1,:]-x2_mean)\n",
    "    sw=(s1+s2)/(shape(X_train)[0]-2)\n",
    "\n",
    "    eigvalue_sw,eigvector_sw=eig(sw)\n",
    "    eigmean=mean(eigvalue_sw)\n",
    "    \n",
    "    for i in range(0,len(eigvalue_sw)):\n",
    "        if eigvalue_sw[i]<eigmean:\n",
    "            eigvalue_sw[i]=eigmean\n",
    "      \n",
    "    sw_new=eigvector_sw.dot(diag(eigvalue_sw)).dot(eigvector_sw.T)\n",
    "    \n",
    "    w=inv(sw_new).dot((x1_mean-x2_mean).T)\n",
    "    w0=(x1_mean+x2_mean).dot(w)/2.\n",
    "    return w, w0\n",
    "\n",
    "def lda_predict(X_test,label_test,w_lda,w_lda0):\n",
    "    X_test_lda=lda_out(w_lda,X_test)\n",
    "    y=X_test_lda-w_lda0 \n",
    "    out=zeros([shape(label_test)[0],1])\n",
    "    ind1=where(y>=0)\n",
    "    ind2=where(y<0)\n",
    "    out[ind1],out[ind2]=1,0\n",
    "    return out\n",
    "\n",
    "def lda_out(w,X_train):\n",
    "    return X_train.dot(w)\n",
    "\n",
    "def sample_arrange(X,label):\n",
    "    x1=X[where(label==1)[0],:]\n",
    "    x2=X[where(label==0)[0],:]\n",
    "    label1=label[where(label==1)[0],:]\n",
    "    label2=label[where(label==0)[0],:]\n",
    "    return x1,x2,label1,label2\n",
    "\n",
    "\n",
    "def confusion_matrix(out,target_num):\n",
    "    ind_TP=where(out[0:target_num]==1)[0]\n",
    "    ind_FP=where(out[target_num:]==1)[0]\n",
    "    ind_TN=where(out[target_num:]==0)[0]\n",
    "    ind_FN=where(out[0:target_num]==0)[0]\n",
    "    TP=len(ind_TP)\n",
    "    FP=len(ind_FP)\n",
    "    TN=len(ind_TN)\n",
    "    FN=len(ind_FN)\n",
    "    P=len(out[0:target_num])\n",
    "    N=len(out[target_num:])\n",
    "    return float(TP), float(FP), float(TN), float(FN), float(P), float(N)\n",
    "\n",
    "def balanced_accuracy(TP,FP,TN,FN):\n",
    "    BA=.5*(TP/(TP+FN)+TN/(TN+FP))\n",
    "    return BA\n",
    "\n",
    "def linear_out(X_test,label_test,y):\n",
    "    out=zeros([shape(label_test)[0],1])\n",
    "    ind1=where(y>=0)\n",
    "    ind2=where(y<0)\n",
    "    out[ind1],out[ind2]=1,0\n",
    "    return out\n",
    "\n",
    "\n",
    "def my_bayes(X,label):\n",
    "    x1,x2,label1,label2=sample_arrange(X,label)\n",
    "    mv1,sig1=mean(x1,axis=0),covariance(x1)\n",
    "    mv2,sig2=mean(x2,axis=0),covariance(x2)\n",
    "    \n",
    "#     eigvalue_sig1,eigvector_sig1=eig(sig1)\n",
    "#     eigmean_sig1=mean(eigvalue_sig1)\n",
    "#     for i in range(0,len(eigvalue_sig1)):\n",
    "#         if eigvalue_sig1[i]<eigmean_sig1:\n",
    "#             eigvalue_sig1[i]=eigmean_sig1\n",
    "#     sig1=eigvector_sig1.dot(diag(eigvalue_sig1)).dot(eigvector_sig1.T)\n",
    "    \n",
    "#     eigvalue_sig2,eigvector_sig2=eig(sig2)\n",
    "#     eigmean_sig2=mean(eigvalue_sig2)\n",
    "#     for i in range(0,len(eigvalue_sig2)):\n",
    "#         if eigvalue_sig2[i]<eigmean_sig2:\n",
    "#             eigvalue_sig2[i]=eigmean_sig2\n",
    "#     sig2=eigvector_sig2.dot(diag(eigvalue_sig2)).dot(eigvector_sig2.T)\n",
    "    \n",
    "    \n",
    "    pro1=float(len(x1))/(len(x1)+len(x2))\n",
    "    pro2=float(len(x2))/(len(x1)+len(x2))\n",
    "    y1=M_pdf(x1,mv1,sig1)\n",
    "    y2=M_pdf(x2,mv2,sig2)\n",
    "    return mv1,sig1,pro1,mv2,sig2,pro2\n",
    "\n",
    "def my_bayes_score(X_test,X_train,label_train):  \n",
    "    mv1,sig1,pro1,mv2,sig2,pro2=my_bayes(X_train,label_train)\n",
    "    y1=M_pdf(X_test,mv1,sig1)\n",
    "    y2=M_pdf(X_test,mv2,sig2)\n",
    "    p1=pro1*y1/EVI(pro1,y1,pro2,y2)\n",
    "    p2=pro2*y2/EVI(pro1,y1,pro2,y2)\n",
    "    return p1,p2\n",
    "\n",
    "def EVI(pro1,y1,pro2,y2):\n",
    "    return y1*pro1+y2*pro2\n",
    "\n",
    "def M_pdf(X,mv,sig):\n",
    "    # X: obs*feature\n",
    "    m,n=shape(X)[0],shape(X)[1]\n",
    "    n=float(n)\n",
    "    exponent=zeros([m,1])\n",
    "    y=zeros([m,1])\n",
    "    for i in range(0,m):\n",
    "        exponent[i,:]=exp( -1./2.*(X[i:i+1,:]-mv).dot(inv(sig)).dot((X[i:i+1,:]-mv).T))\n",
    "        y[i,:]=1./(pow( (2*pi),n/2)*(pow (det(sig),1./2.) ) )*(exponent[i,:])\n",
    "    return y\n",
    "\n",
    "def bayes_predict(X_test,label_test,X_train,label_train,pstar):\n",
    "    p1,p2=my_bayes_score(X_test,X_train,label_train)\n",
    "    out=zeros([shape(label_test)[0],1])\n",
    "    ind1=where(p1>=pstar)\n",
    "    ind2=where(p1<pstar)\n",
    "    out[ind1],out[ind2]=1,0\n",
    "    return out\n",
    "\n",
    "\n",
    "def log_var(epoch):\n",
    "    # epoch: obs*vari\n",
    "    return log10(var(epoch,axis=1,keepdims=True))\n",
    "\n",
    "def plot_style():\n",
    "    font = {'family' : 'normal', 'weight' : 'bold', 'size'   : 14}\n",
    "    rc('font', **font)\n",
    "    rc('axes', linewidth=4)\n",
    "    rc('lines', lw=4)\n",
    "plot_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "if platform.system()=='Windows':\n",
    "    # expert user1 10Hz\n",
    "    expert_user1_10Hz_police='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\expert user1 10Hz\\\\police'\n",
    "    expert_user1_10Hz_nonsmoking='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\expert user1 10Hz\\\\nonsmoking'\n",
    "    expert_user1_10Hz_figure='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\expert user1 10Hz\\\\figure'\n",
    "\n",
    "    # expert user2 10Hz\n",
    "    expert_user2_10Hz_police='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\expert user2 10Hz\\\\police'\n",
    "    expert_user2_10Hz_nonsmoking='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\expert user2 10Hz\\\\nonsmoking'\n",
    "    \n",
    "\n",
    "    # expert user1 5Hz\n",
    "    expert_user1_5Hz_figure='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\expert user1 5Hz\\\\figure'\n",
    "    expert_user1_5Hz_nonsmoking='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\expert user1 5Hz\\\\nonsmoking'\n",
    "    expert_user1_5Hz_police='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\expert user1 5Hz\\\\police'\n",
    "    expert_user1_5Hz_guy='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\expert user1 5Hz\\\\guy'\n",
    "    expert_user1_5Hz_parking='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\expert user1 5Hz\\\\parking'\n",
    "\n",
    "\n",
    "    # expert user2 5Hz\n",
    "    expert_user2_5Hz_nonsmoking='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\expert user2 5Hz\\\\nonsmoking'\n",
    "    expert_user2_5Hz_police='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\expert user2 5Hz\\\\police'\n",
    "    expert_user2_5Hz_figure='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\expert user2 5Hz\\\\figure'\n",
    "    \n",
    "\n",
    "    # expert user5 5Hz\n",
    "    expert_user5_5Hz_police='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\expert user5 5Hz\\\\police'\n",
    "    expert_user5_5Hz_nonsmoking='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\expert user5 5Hz\\\\nonsmoking'\n",
    "    expert_user5_5Hz_figure='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\expert user5 5Hz\\\\figure'\n",
    "    \n",
    "\n",
    "    # nonexpert user3 10 Hz\n",
    "    nonexpert_user3_10Hz_figure='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\nonexpert user3 10Hz\\\\figure'\n",
    "    nonexpert_user3_10Hz_police='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\nonexpert user3 10Hz\\\\police'\n",
    "    nonexpert_user3_10Hz_nonsmoking='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\nonexpert user3 10Hz\\\\nonsmoking'\n",
    "    \n",
    "\n",
    "    # nonexpert user4 5Hz\n",
    "    nonexpert_user4_5Hz_guy='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\nonexpert user4 5Hz\\\\guy'\n",
    "    nonexpert_user4_5Hz_figure='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\nonexpert user4 5Hz\\\\figure'\n",
    "    nonexpert_user4_5Hz_nonsmoking='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\nonexpert user4 5Hz\\\\nonsmoking'\n",
    "    \n",
    "\n",
    "    # nonexpert user6 5Hz\n",
    "    nonexpert_user6_5Hz_figure='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\nonexpert user6 5Hz\\\\figure'\n",
    "    nonexpert_user6_5Hz_nonsmoking='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\nonexpert user6 5Hz\\\\nonsmoking'\n",
    "    nonexpert_user6_5Hz_police='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\nonexpert user6 5Hz\\\\police'\n",
    "    \n",
    "\n",
    "    # nonexpert user7 5Hz\n",
    "    nonexpert_user7_5Hz_figure='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\nonexpert user7 5Hz\\\\figure'\n",
    "    nonexpert_user7_5Hz_nonsmoking='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\nonexpert user7 5Hz\\\\nonsmoking'\n",
    "    nonexpert_user7_5Hz_guy='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\nonexpert user7 5Hz\\\\guy'\n",
    "    nonexpert_user7_5Hz_police='D:\\\\application\\\\google cloud\\\\workspace\\\\cost_leanrning_lda\\\\data_set\\\\nonexpert user7 5Hz\\\\police'\n",
    "    \n",
    "elif platform.system()=='Darwin':\n",
    "    expert_user1_10Hz_police='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/expert user1 10Hz/police'\n",
    "    expert_user1_10Hz_nonsmoking='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/expert user1 10Hz/nonsmoking'\n",
    "    expert_user1_10Hz_figure='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/expert user1 10Hz/figure'\n",
    "\n",
    "    expert_user2_10Hz_police='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/expert user2 10Hz/police'\n",
    "    expert_user2_10Hz_nonsmoking='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/expert user2 10Hz/nonsmoking'\n",
    "\n",
    "    expert_user1_5Hz_figure='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/expert user1 5Hz/figure'\n",
    "    expert_user1_5Hz_nonsmoking='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/expert user1 5Hz/nonsmoking'\n",
    "    expert_user1_5Hz_police='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/expert user1 5Hz/police'\n",
    "    expert_user1_5Hz_guy='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/expert user1 5Hz/guy'\n",
    "    expert_user1_5Hz_parking='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/expert user1 5Hz/parking'\n",
    "\n",
    "    expert_user2_5Hz_nonsmoking='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/expert user2 5Hz/nonsmoking'\n",
    "    expert_user2_5Hz_police='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/expert user2 5Hz/police'\n",
    "    expert_user2_5Hz_figure='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/expert user2 5Hz/figure'\n",
    "\n",
    "    expert_user5_5Hz_police='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/expert user5 5Hz/police'\n",
    "    expert_user5_5Hz_nonsmoking='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/expert user5 5Hz/nonsmoking'\n",
    "    expert_user5_5Hz_figure='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/expert user5 5Hz/figure'\n",
    "\n",
    "    nonexpert_user3_10Hz_figure='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/nonexpert user3 10Hz/figure'\n",
    "    nonexpert_user3_10Hz_police='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/nonexpert user3 10Hz/police'\n",
    "    nonexpert_user3_10Hz_nonsmoking='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/nonexpert user3 10Hz/nonsmoking'\n",
    "\n",
    "    nonexpert_user4_5Hz_guy='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/nonexpert user4 5Hz/guy'\n",
    "    nonexpert_user4_5Hz_figure='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/nonexpert user4 5Hz/figure'\n",
    "    nonexpert_user4_5Hz_nonsmoking='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/nonexpert user4 5Hz/nonsmoking'\n",
    "\n",
    "    nonexpert_user6_5Hz_figure='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/nonexpert user6 5Hz/figure'\n",
    "    nonexpert_user6_5Hz_nonsmoking='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/nonexpert user6 5Hz/nonsmoking'\n",
    "    nonexpert_user6_5Hz_police='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/nonexpert user6 5Hz/police'\n",
    "\n",
    "    nonexpert_user7_5Hz_figure='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/nonexpert user7 5Hz/figure'\n",
    "    nonexpert_user7_5Hz_nonsmoking='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/nonexpert user7 5Hz/nonsmoking'\n",
    "    nonexpert_user7_5Hz_guy='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/nonexpert user7 5Hz/guy'\n",
    "    nonexpert_user7_5Hz_police='/Users/Villa/Google Drive/workspace/cost_leanrning_lda/data_set/nonexpert user7 5Hz/police'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "data_path=[expert_user1_10Hz_police,expert_user1_10Hz_nonsmoking,expert_user1_10Hz_figure,\\\n",
    "          expert_user2_10Hz_police,expert_user2_10Hz_nonsmoking,\\\n",
    "          expert_user1_5Hz_figure,expert_user1_5Hz_nonsmoking,expert_user1_5Hz_police,expert_user1_5Hz_guy,expert_user1_5Hz_parking,\\\n",
    "          expert_user2_5Hz_nonsmoking,expert_user2_5Hz_police,expert_user2_5Hz_figure,\\\n",
    "          expert_user5_5Hz_police,expert_user5_5Hz_nonsmoking,expert_user5_5Hz_figure,\\\n",
    "          nonexpert_user3_10Hz_figure,nonexpert_user3_10Hz_nonsmoking,nonexpert_user3_10Hz_police,\\\n",
    "          nonexpert_user4_5Hz_guy,nonexpert_user4_5Hz_figure,nonexpert_user4_5Hz_nonsmoking,\\\n",
    "          nonexpert_user6_5Hz_figure,nonexpert_user6_5Hz_nonsmoking,nonexpert_user6_5Hz_police,\\\n",
    "          nonexpert_user7_5Hz_figure,nonexpert_user7_5Hz_nonsmoking,nonexpert_user7_5Hz_guy,nonexpert_user7_5Hz_police]\n",
    " \n",
    "data_sub1=[expert_user1_10Hz_police,expert_user1_10Hz_nonsmoking,expert_user1_10Hz_figure] \n",
    "data_sub2=[expert_user2_10Hz_police,expert_user2_10Hz_nonsmoking]\n",
    "data_sub3=[expert_user1_5Hz_figure,expert_user1_5Hz_nonsmoking,expert_user1_5Hz_police] #,expert_user1_5Hz_guy,expert_user1_5Hz_parking\n",
    "data_sub4=[expert_user2_5Hz_nonsmoking,expert_user2_5Hz_police,expert_user2_5Hz_figure]\n",
    "data_sub5=[expert_user5_5Hz_police,expert_user5_5Hz_nonsmoking,expert_user5_5Hz_figure]\n",
    "data_sub6=[nonexpert_user3_10Hz_figure,nonexpert_user3_10Hz_nonsmoking,nonexpert_user3_10Hz_police]\n",
    "data_sub7=[nonexpert_user4_5Hz_guy,nonexpert_user4_5Hz_figure,nonexpert_user4_5Hz_nonsmoking]\n",
    "data_sub8=[nonexpert_user6_5Hz_figure,nonexpert_user6_5Hz_nonsmoking,nonexpert_user6_5Hz_police]\n",
    "data_sub9=[nonexpert_user7_5Hz_figure,nonexpert_user7_5Hz_nonsmoking,nonexpert_user7_5Hz_police] #,nonexpert_user7_5Hz_guy\n",
    "data_sub=[data_sub1,data_sub2,data_sub3,data_sub4,data_sub5,data_sub6,data_sub7,data_sub8,data_sub9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sub-band CSTP cost learning training and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:113: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:114: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:116: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:117: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:124: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:125: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:127: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:128: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:135: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:136: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:138: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:139: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:152: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:153: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:160: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:161: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:168: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:169: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:179: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:180: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:186: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:187: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:193: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:194: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:151: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:154: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:159: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:284: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: 1\n",
      "dataset: 2\n",
      "dataset: 3\n",
      "dataset: 4\n",
      "dataset: 5\n",
      "dataset: 6\n",
      "dataset: 7\n",
      "dataset: 8\n",
      "dataset: 9\n",
      "0.684307992203 0.668908382066 0.68693957115\n",
      "downsampling 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:285: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:292: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:293: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:300: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:301: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:311: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:312: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:318: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:319: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:325: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:326: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# 3000 tirals in each training and testing, separate train and testing data set \n",
    "target_AC_linear_train=[]\n",
    "standard_AC_linear_train=[]\n",
    "BA_linear_train=[]\n",
    "\n",
    "target_AC_lda_train=[]\n",
    "standard_AC_lda_train=[]\n",
    "BA_lda_train=[]\n",
    "lda_project=[]\n",
    "\n",
    "target_AC_svm_train=[]\n",
    "standard_AC_svm_train=[]\n",
    "BA_svm_train=[]\n",
    "\n",
    "target_AC_bayes_train=[]\n",
    "standard_AC_bayes_train=[]\n",
    "BA_bayes_train=[]\n",
    "\n",
    "target_AC_linear_test=[]\n",
    "standard_AC_linear_test=[]\n",
    "BA_linear_test=[]\n",
    "\n",
    "target_AC_lda_test=[]\n",
    "standard_AC_lda_test=[]\n",
    "BA_lda_test=[]\n",
    "\n",
    "target_AC_svm_test=[]\n",
    "standard_AC_svm_test=[]\n",
    "BA_svm_test=[]\n",
    "\n",
    "target_AC_bayes_test=[]\n",
    "standard_AC_bayes_test=[]\n",
    "BA_bayes_test=[]\n",
    "# len(data_sub)\n",
    "for i in range(0,9):\n",
    "    variable,chan=shape(load_epoch(data_path[0],'epoch_target'))[1], 32\n",
    "    dataset=data_sub[i]\n",
    "    percent=.9  # training rate\n",
    "    test_percent=1-percent # testing rate\n",
    "    portion=.99 # base rate in training session\n",
    "    \n",
    "    epoch_target_dataset=[]\n",
    "    epoch_standard_dataset=[]\n",
    "    epoch_target=zeros([1,variable,chan])\n",
    "    epoch_standard=zeros([1,variable,chan])\n",
    "    for j in range(0,len(dataset)):\n",
    "        epoch_target_dataset.append(load_epoch(dataset[j],'epoch_target'))\n",
    "        epoch_standard_dataset.append(load_epoch(dataset[j],'epoch_standard')) # chan variable obs\n",
    "        epoch_target_32,epoch_standard_32=epoch_target_dataset[j], epoch_standard_dataset[j]\n",
    "        epoch_target_6,epoch_standard_6=epoch_target_32[:,:,:],\\\n",
    "                                        epoch_standard_32[:,:,:]\n",
    "#         epoch_target_6,epoch_standard_6=epoch_target_32[array([2,24,13,14,19,17,16,18])-1,:,:],\\\n",
    "#                                         epoch_standard_32[array([2,24,13,14,19,17,16,18])-1,:,:]\n",
    "        epoch_target_6,epoch_standard_6=epoch_target_6.T, epoch_standard_6.T    # obs variable chan\n",
    "        epoch_target=r_[epoch_target, epoch_target_6]\n",
    "        epoch_standard=r_[epoch_standard, epoch_standard_6]\n",
    "    epoch_target=epoch_target[1:,:,:]    \n",
    "    epoch_standard=epoch_standard[1:,:,:]\n",
    "\n",
    "    flag=shape(epoch_target)[0]+shape(epoch_standard)[0] # total number of epochs\n",
    "    num_t=shape(epoch_target)[0] # number of target\n",
    "    num_s=shape(epoch_standard)[0] # number of standard\n",
    "    epoch_all= r_[epoch_target,epoch_standard]\n",
    "     \n",
    "#   ----------------------------------------------filter-------------------------------------\n",
    "#   0-5Hz  \n",
    "    epoch_all_0_5=zeros_like(epoch_all)\n",
    "    for j in range(0,chan):\n",
    "        epoch_all_0_5[:,:,j]=butter_bandpass_filter(epoch_all[:,:,j], .1, 5, 250, order=3)\n",
    "\n",
    "    \n",
    "#   5-10Hz  \n",
    "    epoch_all_5_10=zeros_like(epoch_all)\n",
    "    for j in range(0,chan):\n",
    "        epoch_all_5_10[:,:,j]=butter_bandpass_filter(epoch_all[:,:,j], 5, 10, 250, order=3)   \n",
    "    \n",
    "#   10-15Hz  \n",
    "    epoch_all_10_15=zeros_like(epoch_all)\n",
    "    for j in range(0,chan):\n",
    "        epoch_all_10_15[:,:,j]=butter_bandpass_filter(epoch_all[:,:,j], 10, 15, 250, order=3)    \n",
    "\n",
    "\n",
    "#   --------------------------------------------construct sub band training and testing epochs for CSTP--------------------------------\n",
    "    # 0-5Hz\n",
    "    epoch_target_train_0_5, epoch_target_test_0_5=cross_validation.train_test_split(epoch_all_0_5[0:num_t,:,:], train_size=percent,random_state=42)\n",
    "    epoch_standard_train_0_5, epoch_standard_test_0_5=cross_validation.train_test_split(epoch_all_0_5[num_t:,:,:], train_size=percent,random_state=42)\n",
    "    epoch_train_0_5=r_[epoch_target_train_0_5,epoch_standard_train_0_5]\n",
    "    label_train=r_[ones(shape(epoch_target_train_0_5)[0]),zeros(shape(epoch_standard_train_0_5)[0])]\n",
    "    epoch_test_0_5=r_[epoch_target_test_0_5,epoch_standard_test_0_5]\n",
    "    label_test=r_[ones(shape(epoch_target_test_0_5)[0]),zeros(shape(epoch_standard_test_0_5)[0])]\n",
    "    \n",
    "    # 5-10Hz\n",
    "    epoch_target_train_5_10, epoch_target_test_5_10=cross_validation.train_test_split(epoch_all_5_10[0:num_t,:,:], train_size=percent,random_state=42)\n",
    "    epoch_standard_train_5_10, epoch_standard_test_5_10=cross_validation.train_test_split(epoch_all_5_10[num_t:,:,:], train_size=percent,random_state=42)\n",
    "    epoch_train_5_10=r_[epoch_target_train_5_10,epoch_standard_train_5_10]\n",
    "    epoch_test_5_10=r_[epoch_target_test_5_10,epoch_standard_test_5_10]\n",
    "    \n",
    "    # 10-15Hz\n",
    "    epoch_target_train_10_15, epoch_target_test_10_15=cross_validation.train_test_split(epoch_all_10_15[0:num_t,:,:], train_size=percent,random_state=42)\n",
    "    epoch_standard_train_10_15, epoch_standard_test_10_15=cross_validation.train_test_split(epoch_all_10_15[num_t:,:,:], train_size=percent,random_state=42)\n",
    "    epoch_train_10_15=r_[epoch_target_train_10_15,epoch_standard_train_10_15]\n",
    "    epoch_test_10_15=r_[epoch_target_test_10_15,epoch_standard_test_10_15]\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------CSTP calculation----------------------------------------\n",
    "    # train 300-500\n",
    "    downsampling=5\n",
    "    # 0-5Hz\n",
    "    cs_pattern_0_5,cs_filter_0_5=myCSP(epoch_train_0_5[:,300:500,:],label_train)\n",
    "    ct_pattern_0_5, ct_filter_0_5=myCTP(epoch_train_0_5[:,300:500,:],label_train,downsampling)\n",
    "\n",
    "    ind_eig_cs1_0_5=max_target_lamba_ind(epoch_train_0_5[0:num_t*percent,300:500,:],epoch_train_0_5[num_t*percent:,300:500,:],cs_pattern_0_5,cs_filter_0_5)\n",
    "    ind_eig_ct1_0_5=max_target_lamba_ind(transpose(epoch_train_0_5[0:num_t*percent,300:500:downsampling,:],(0,2,1)),\\\n",
    "                                  transpose(epoch_train_0_5[num_t*percent:,300:500:downsampling,:],(0,2,1)),ct_pattern_0_5,ct_filter_0_5)\n",
    "\n",
    "    ind_eig_cs2_0_5=max_target_lamba_ind(epoch_train_0_5[num_t*percent:,300:500,:],epoch_train_0_5[0:num_t*percent,300:500,:],cs_pattern_0_5,cs_filter_0_5)\n",
    "    ind_eig_ct2_0_5=max_target_lamba_ind(transpose(epoch_train_0_5[num_t*percent:,300:500:downsampling,:],(0,2,1)),\\\n",
    "                                  transpose(epoch_train_0_5[0:num_t*percent,300:500:downsampling,:],(0,2,1)),ct_pattern_0_5,ct_filter_0_5)\n",
    "    \n",
    "\n",
    "    # 5-10Hz\n",
    "    cs_pattern_5_10,cs_filter_5_10=myCSP(epoch_train_5_10[:,300:500,:],label_train)\n",
    "    ct_pattern_5_10, ct_filter_5_10=myCTP(epoch_train_5_10[:,300:500,:],label_train,downsampling)\n",
    "\n",
    "    ind_eig_cs1_5_10=max_target_lamba_ind\\\n",
    "                    (epoch_train_5_10[0:num_t*percent,300:500,:],epoch_train_5_10[num_t*percent:,300:500,:],cs_pattern_5_10,cs_filter_5_10)\n",
    "    ind_eig_ct1_5_10=max_target_lamba_ind(transpose(epoch_train_5_10[0:num_t*percent,300:500:downsampling,:],(0,2,1)),\\\n",
    "                                  transpose(epoch_train_5_10[num_t*percent:,300:500:downsampling,:],(0,2,1)),ct_pattern_5_10,ct_filter_5_10)\n",
    "\n",
    "    ind_eig_cs2_5_10=max_target_lamba_ind\\\n",
    "                    (epoch_train_5_10[num_t*percent:,300:500,:],epoch_train_5_10[0:num_t*percent,300:500,:],cs_pattern_5_10,cs_filter_5_10)\n",
    "    ind_eig_ct2_5_10=max_target_lamba_ind(transpose(epoch_train_5_10[num_t*percent:,300:500:downsampling,:],(0,2,1)),\\\n",
    "                                  transpose(epoch_train_5_10[0:num_t*percent,300:500:downsampling,:],(0,2,1)),ct_pattern_5_10,ct_filter_5_10)\n",
    "    \n",
    "    \n",
    "    # 10-15Hz\n",
    "    cs_pattern_10_15,cs_filter_10_15=myCSP(epoch_train_10_15[:,300:500,:],label_train)\n",
    "    ct_pattern_10_15, ct_filter_10_15=myCTP(epoch_train_10_15[:,300:500,:],label_train,downsampling)\n",
    "\n",
    "    ind_eig_cs1_10_15=max_target_lamba_ind\\\n",
    "                      (epoch_train_10_15[0:num_t*percent,300:500,:],epoch_train_10_15[num_t*percent:,300:500,:],cs_pattern_10_15,cs_filter_10_15)\n",
    "    ind_eig_ct1_10_15=max_target_lamba_ind(transpose(epoch_train_10_15[0:num_t*percent,300:500:downsampling,:],(0,2,1)),\\\n",
    "                                  transpose(epoch_train_10_15[num_t*percent:,300:500:downsampling,:],(0,2,1)),ct_pattern_10_15,ct_filter_10_15)\n",
    "\n",
    "    ind_eig_cs2_10_15=max_target_lamba_ind\\\n",
    "                     (epoch_train_10_15[num_t*percent:,300:500,:],epoch_train_10_15[0:num_t*percent,300:500,:],cs_pattern_10_15,cs_filter_10_15)\n",
    "    ind_eig_ct2_10_15=max_target_lamba_ind(transpose(epoch_train_10_15[num_t*percent:,300:500:downsampling,:],(0,2,1)),\\\n",
    "                                  transpose(epoch_train_10_15[0:num_t*percent,300:500:downsampling,:],(0,2,1)),ct_pattern_10_15,ct_filter_10_15)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # -------------------------------------------CSTP training feature selection-----------------------------------\n",
    "    # CSP feature\n",
    "    # 0-5Hz\n",
    "    cs_filter_para_eig1_0_5=cs_filter_0_5[ind_eig_cs1_0_5,:]\n",
    "    cs_filter_para_eig2_0_5=cs_filter_0_5[ind_eig_cs2_0_5,:]\n",
    "    epoch_cs_filter_eig1_0_5=signal_projection(cs_filter_para_eig1_0_5, epoch_train_0_5[:,300:500,:])\n",
    "    epoch_cs_filter_eig2_0_5=signal_projection(cs_filter_para_eig2_0_5, epoch_train_0_5[:,300:500,:])\n",
    "    target_cs_filter_eig1_0_5,target_cs_filter_eig2_0_5=epoch_cs_filter_eig1_0_5[0:num_t*percent,:], epoch_cs_filter_eig2_0_5[0:num_t*percent,:]\n",
    "    standard_cs_filter_eig1_0_5,standard_cs_filter_eig2_0_5=epoch_cs_filter_eig1_0_5[num_t*percent:,:], epoch_cs_filter_eig2_0_5[num_t*percent:,:]\n",
    "    \n",
    "    # 5-10Hz\n",
    "    cs_filter_para_eig1_5_10=cs_filter_5_10[ind_eig_cs1_5_10,:]\n",
    "    cs_filter_para_eig2_5_10=cs_filter_5_10[ind_eig_cs2_5_10,:]\n",
    "    epoch_cs_filter_eig1_5_10=signal_projection(cs_filter_para_eig1_5_10, epoch_train_5_10[:,300:500,:])\n",
    "    epoch_cs_filter_eig2_5_10=signal_projection(cs_filter_para_eig2_5_10, epoch_train_5_10[:,300:500,:])\n",
    "    target_cs_filter_eig1_5_10,target_cs_filter_eig2_5_10=epoch_cs_filter_eig1_5_10[0:num_t*percent,:], epoch_cs_filter_eig2_5_10[0:num_t*percent,:]\n",
    "    standard_cs_filter_eig1_5_10,standard_cs_filter_eig2_5_10=epoch_cs_filter_eig1_5_10[num_t*percent:,:], epoch_cs_filter_eig2_5_10[num_t*percent:,:]\n",
    "    \n",
    "    # 10-15Hz\n",
    "    cs_filter_para_eig1_10_15=cs_filter_10_15[ind_eig_cs1_10_15,:]\n",
    "    cs_filter_para_eig2_10_15=cs_filter_10_15[ind_eig_cs2_10_15,:]\n",
    "    epoch_cs_filter_eig1_10_15=signal_projection(cs_filter_para_eig1_10_15, epoch_train_10_15[:,300:500,:])\n",
    "    epoch_cs_filter_eig2_10_15=signal_projection(cs_filter_para_eig2_0_5, epoch_train_10_15[:,300:500,:])\n",
    "    target_cs_filter_eig1_10_15,target_cs_filter_eig2_10_15=epoch_cs_filter_eig1_10_15[0:num_t*percent,:], epoch_cs_filter_eig2_10_15[0:num_t*percent,:]\n",
    "    standard_cs_filter_eig1_10_15,standard_cs_filter_eig2_10_15=epoch_cs_filter_eig1_10_15[num_t*percent:,:], epoch_cs_filter_eig2_10_15[num_t*percent:,:]\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # CTP feature\n",
    "    # 0-5Hz\n",
    "    epoch_ct_filter_eig1_0_5=signal_projection(ct_filter_0_5[ind_eig_ct1_0_5,:], transpose(epoch_train_0_5[:,300:500:downsampling,:],(0,2,1)))\n",
    "    epoch_ct_filter_eig2_0_5=signal_projection(ct_filter_0_5[ind_eig_ct2_0_5,:], transpose(epoch_train_0_5[:,300:500:downsampling,:],(0,2,1)))\n",
    "    target_ct_filter_eig1_0_5,target_ct_filter_eig2_0_5=epoch_ct_filter_eig1_0_5[0:num_t*percent,:], epoch_ct_filter_eig2_0_5[0:num_t*percent,:]\n",
    "    standard_ct_filter_eig1_0_5,standard_ct_filter_eig2_0_5=epoch_ct_filter_eig1_0_5[num_t*percent:,:], epoch_ct_filter_eig2_0_5[num_t*percent:,:]\n",
    "    \n",
    "    \n",
    "    # 5-10Hz\n",
    "    epoch_ct_filter_eig1_5_10=signal_projection(ct_filter_5_10[ind_eig_ct1_5_10,:], transpose(epoch_train_5_10[:,300:500:downsampling,:],(0,2,1)))\n",
    "    epoch_ct_filter_eig2_5_10=signal_projection(ct_filter_5_10[ind_eig_ct2_5_10,:], transpose(epoch_train_5_10[:,300:500:downsampling,:],(0,2,1)))\n",
    "    target_ct_filter_eig1_5_10,target_ct_filter_eig2_5_10=epoch_ct_filter_eig1_5_10[0:num_t*percent,:], epoch_ct_filter_eig2_5_10[0:num_t*percent,:]\n",
    "    standard_ct_filter_eig1_5_10,standard_ct_filter_eig2_5_10=epoch_ct_filter_eig1_5_10[num_t*percent:,:], epoch_ct_filter_eig2_5_10[num_t*percent:,:]\n",
    "    \n",
    "    \n",
    "    # 10-15Hz\n",
    "    epoch_ct_filter_eig1_10_15=signal_projection(ct_filter_10_15[ind_eig_ct1_10_15,:], transpose(epoch_train_10_15[:,300:500:downsampling,:],(0,2,1)))\n",
    "    epoch_ct_filter_eig2_10_15=signal_projection(ct_filter_10_15[ind_eig_ct2_10_15,:], transpose(epoch_train_10_15[:,300:500:downsampling,:],(0,2,1)))\n",
    "    target_ct_filter_eig1_10_15,target_ct_filter_eig2_10_15=epoch_ct_filter_eig1_10_15[0:num_t*percent,:], epoch_ct_filter_eig2_10_15[0:num_t*percent,:]\n",
    "    standard_ct_filter_eig1_10_15,standard_ct_filter_eig2_10_15=epoch_ct_filter_eig1_10_15[num_t*percent:,:], epoch_ct_filter_eig2_10_15[num_t*percent:,:]\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "    target_feature_train=c_[log_var(target_cs_filter_eig1_0_5[:,:]),\\\n",
    "                                                log_var(target_cs_filter_eig2_0_5[:,:]),\\\n",
    "                                                log_var(target_ct_filter_eig1_0_5),\\\n",
    "                                                log_var(target_ct_filter_eig2_0_5),\\\n",
    "                                                \n",
    "                                                log_var(target_cs_filter_eig1_5_10[:,:]),\\\n",
    "                                                log_var(target_cs_filter_eig2_5_10[:,:]),\\\n",
    "                                                log_var(target_ct_filter_eig1_5_10),\\\n",
    "                                                log_var(target_ct_filter_eig2_5_10),\\\n",
    "                                                \n",
    "                                                log_var(target_cs_filter_eig1_10_15[:,:]),\\\n",
    "                                                log_var(target_cs_filter_eig2_10_15[:,:]),\\\n",
    "                                                log_var(target_ct_filter_eig1_10_15),\\\n",
    "                                                log_var(target_ct_filter_eig2_10_15)]\n",
    "                                                \n",
    "\n",
    "    standard_feature_train=c_[log_var(standard_cs_filter_eig1_0_5[:,:]),\\\n",
    "                                                log_var(standard_cs_filter_eig2_0_5[:,:]),\\\n",
    "                                                log_var(standard_ct_filter_eig1_0_5),\\\n",
    "                                                log_var(standard_ct_filter_eig2_0_5),\\\n",
    "                                                \n",
    "                                                log_var(standard_cs_filter_eig1_5_10[:,:]),\\\n",
    "                                                log_var(standard_cs_filter_eig2_5_10[:,:]),\\\n",
    "                                                log_var(standard_ct_filter_eig1_5_10),\\\n",
    "                                                log_var(standard_ct_filter_eig2_5_10),\\\n",
    "                                                \n",
    "                                                log_var(standard_cs_filter_eig1_10_15[:,:]),\\\n",
    "                                                log_var(standard_cs_filter_eig2_10_15[:,:]),\\\n",
    "                                                log_var(standard_ct_filter_eig1_10_15),\\\n",
    "                                                log_var(standard_ct_filter_eig2_10_15)]\n",
    "                                                \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    standard_feature_train_portion,standard_feature_test_portion=cross_validation.train_test_split(standard_feature_train, train_size=portion,random_state=42)\n",
    "    \n",
    "    label_train_eig=r_[ones([shape(target_feature_train)[0],1]),zeros([shape(standard_feature_train_portion[:,:])[0],1])]\n",
    "    \n",
    "    X_train_eig=r_[target_feature_train,standard_feature_train_portion[:,:]]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    #------------------------------------------------classification------------------------------------------\n",
    "    # trianning LDA\n",
    "    w_lda,w_lda0=my_new_lda(X_train_eig,label_train_eig)\n",
    "    lda_project.append(lda_out(w_lda,X_train_eig)[:,0])\n",
    "    out_lda=lda_predict(X_train_eig,label_train_eig,w_lda,w_lda0)\n",
    "    TP_lda, FP_lda, TN_lda, FN_lda, P_lda, N_lda=confusion_matrix(out_lda,num_t*percent)\n",
    "    target_AC_lda_train.append(TP_lda/(TP_lda+FN_lda))\n",
    "    standard_AC_lda_train.append(TN_lda/(TN_lda+FP_lda))\n",
    "    BA_lda_train.append((target_AC_lda_train[i]+standard_AC_lda_train[i])/2)\n",
    "\n",
    "    \n",
    "    \n",
    "    # training SVM\n",
    "    class_SVM=float(num_s)/num_t\n",
    "    class_SVM=float(num_s*portion)/num_t\n",
    "    svm_model=svm.LinearSVC(C=.1,class_weight={1:class_SVM})\n",
    "    svm_model.fit(X_train_eig,label_train_eig)\n",
    "    out_svm=svm_model.predict(X_train_eig)\n",
    "    TP_svm, FP_svm, TN_svm, FN_svm, P_svm, N_svm=confusion_matrix(out_svm,num_t*percent)\n",
    "    target_AC_svm_train.append(TP_svm/(TP_svm+FN_svm))\n",
    "    standard_AC_svm_train.append(TN_svm/(TN_svm+FP_svm))\n",
    "    BA_svm_train.append((target_AC_svm_train[i]+standard_AC_svm_train[i])/2)\n",
    "    \n",
    "    \n",
    "\n",
    "    # trainning lda-bayes learning\n",
    "    pstar_lda=float(num_t)/(float(num_s*portion)+float(num_t))\n",
    "    w_lda,w_lda0=my_new_lda(X_train_eig,label_train_eig)\n",
    "    x_lda_out=lda_out(w_lda, X_train_eig)\n",
    "    out_bayes=bayes_predict(x_lda_out, label_train_eig, x_lda_out,label_train_eig,pstar_lda)\n",
    "    TP_bayes, FP_bayes, TN_bayes, FN_bayes, P_bayes, N_bayes=confusion_matrix(out_bayes,num_t*percent)\n",
    "    target_AC_bayes_train.append(TP_bayes/(TP_bayes+FN_bayes))\n",
    "    standard_AC_bayes_train.append(TN_bayes/(TN_bayes+FP_bayes))\n",
    "    BA_bayes_train.append((target_AC_bayes_train[i]+standard_AC_bayes_train[i])/2)\n",
    "    \n",
    "    \n",
    "    # -------------------------------------------CSTP testing feature selection-----------------------------------\n",
    "    # CSP feature\n",
    "    # 0-5Hz\n",
    "    cs_filter_para_eig1_0_5_test=cs_filter_0_5[ind_eig_cs1_0_5,:]\n",
    "    cs_filter_para_eig2_0_5_test=cs_filter_0_5[ind_eig_cs2_0_5,:]\n",
    "    epoch_cs_filter_eig1_0_5_test=signal_projection(cs_filter_para_eig1_0_5, epoch_test_0_5[:,300:500,:])\n",
    "    epoch_cs_filter_eig2_0_5_test=signal_projection(cs_filter_para_eig2_0_5, epoch_test_0_5[:,300:500,:])\n",
    "    target_cs_filter_eig1_0_5_test,target_cs_filter_eig2_0_5_test=epoch_cs_filter_eig1_0_5_test[0:round(num_t*(1-percent)),:], epoch_cs_filter_eig2_0_5_test[0:round(num_t*(1-percent)),:]\n",
    "    standard_cs_filter_eig1_0_5_test,standard_cs_filter_eig2_0_5_test=epoch_cs_filter_eig1_0_5_test[round(num_t*(1-percent)):,:], epoch_cs_filter_eig2_0_5_test[round(num_t*(1-percent)):,:]\n",
    "    \n",
    "    # 5-10Hz\n",
    "    cs_filter_para_eig1_5_10_test=cs_filter_5_10[ind_eig_cs1_5_10,:]\n",
    "    cs_filter_para_eig2_5_10_test=cs_filter_5_10[ind_eig_cs2_5_10,:]\n",
    "    epoch_cs_filter_eig1_5_10_test=signal_projection(cs_filter_para_eig1_5_10_test, epoch_test_5_10[:,300:500,:])\n",
    "    epoch_cs_filter_eig2_5_10_test=signal_projection(cs_filter_para_eig2_5_10_test, epoch_test_5_10[:,300:500,:])\n",
    "    target_cs_filter_eig1_5_10_test,target_cs_filter_eig2_5_10_test=epoch_cs_filter_eig1_5_10_test[0:round(num_t*(1-percent)),:], epoch_cs_filter_eig2_5_10_test[0:round(num_t*(1-percent)),:]\n",
    "    standard_cs_filter_eig1_5_10_test,standard_cs_filter_eig2_5_10_test=epoch_cs_filter_eig1_5_10_test[round(num_t*(1-percent)):,:], epoch_cs_filter_eig2_5_10_test[round(num_t*(1-percent)):,:]\n",
    "    \n",
    "    # 10-15Hz\n",
    "    cs_filter_para_eig1_10_15_test=cs_filter_10_15[ind_eig_cs1_10_15,:]\n",
    "    cs_filter_para_eig2_10_15_test=cs_filter_10_15[ind_eig_cs2_10_15,:]\n",
    "    epoch_cs_filter_eig1_10_15_test=signal_projection(cs_filter_para_eig1_10_15_test, epoch_test_10_15[:,300:500,:])\n",
    "    epoch_cs_filter_eig2_10_15_test=signal_projection(cs_filter_para_eig2_10_15_test, epoch_test_10_15[:,300:500,:])\n",
    "    target_cs_filter_eig1_10_15_test,target_cs_filter_eig2_10_15_test=epoch_cs_filter_eig1_10_15_test[0:round(num_t*(1-percent)),:], epoch_cs_filter_eig2_10_15_test[0:round(num_t*(1-percent)),:]\n",
    "    standard_cs_filter_eig1_10_15_test,standard_cs_filter_eig2_10_15_test=epoch_cs_filter_eig1_10_15_test[round(num_t*(1-percent)):,:], epoch_cs_filter_eig2_10_15_test[round(num_t*(1-percent)):,:]\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # CTP feature\n",
    "    # 0-5Hz\n",
    "    epoch_ct_filter_eig1_0_5_test=signal_projection(ct_filter_0_5[ind_eig_ct1_0_5,:], transpose(epoch_test_0_5[:,300:500:downsampling,:],(0,2,1)))\n",
    "    epoch_ct_filter_eig2_0_5_test=signal_projection(ct_filter_0_5[ind_eig_ct2_0_5,:], transpose(epoch_test_0_5[:,300:500:downsampling,:],(0,2,1)))\n",
    "    target_ct_filter_eig1_0_5_test,target_ct_filter_eig2_0_5_test=epoch_ct_filter_eig1_0_5_test[0:round(num_t*(1-percent)),:], epoch_ct_filter_eig2_0_5_test[0:round(num_t*(1-percent)),:]\n",
    "    standard_ct_filter_eig1_0_5_test,standard_ct_filter_eig2_0_5_test=epoch_ct_filter_eig1_0_5_test[round(num_t*(1-percent)):,:], epoch_ct_filter_eig2_0_5_test[round(num_t*(1-percent)):,:]\n",
    "    \n",
    "    \n",
    "    # 5-10Hz\n",
    "    epoch_ct_filter_eig1_5_10_test=signal_projection(ct_filter_5_10[ind_eig_ct1_5_10,:], transpose(epoch_test_5_10[:,300:500:downsampling,:],(0,2,1)))\n",
    "    epoch_ct_filter_eig2_5_10_test=signal_projection(ct_filter_5_10[ind_eig_ct2_5_10,:], transpose(epoch_test_5_10[:,300:500:downsampling,:],(0,2,1)))\n",
    "    target_ct_filter_eig1_5_10_test,target_ct_filter_eig2_5_10_test=epoch_ct_filter_eig1_5_10_test[0:round(num_t*(1-percent)),:], epoch_ct_filter_eig2_5_10_test[0:round(num_t*(1-percent)),:]\n",
    "    standard_ct_filter_eig1_5_10_test,standard_ct_filter_eig2_5_10_test=epoch_ct_filter_eig1_5_10_test[round(num_t*(1-percent)):,:], epoch_ct_filter_eig2_5_10_test[round(num_t*(1-percent)):,:]\n",
    "    \n",
    "    \n",
    "    # 10-15Hz\n",
    "    epoch_ct_filter_eig1_10_15_test=signal_projection(ct_filter_10_15[ind_eig_ct1_10_15,:], transpose(epoch_test_10_15[:,300:500:downsampling,:],(0,2,1)))\n",
    "    epoch_ct_filter_eig2_10_15_test=signal_projection(ct_filter_10_15[ind_eig_ct2_10_15,:], transpose(epoch_test_10_15[:,300:500:downsampling,:],(0,2,1)))\n",
    "    target_ct_filter_eig1_10_15_test,target_ct_filter_eig2_10_15_test=epoch_ct_filter_eig1_10_15_test[0:round(num_t*(1-percent)),:], epoch_ct_filter_eig2_10_15_test[0:round(num_t*(1-percent)),:]\n",
    "    standard_ct_filter_eig1_10_15_test,standard_ct_filter_eig2_10_15_test=epoch_ct_filter_eig1_10_15_test[round(num_t*(1-percent)):,:], epoch_ct_filter_eig2_10_15_test[round(num_t*(1-percent)):,:]\n",
    "    \n",
    "    \n",
    "     \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    target_feature_test=c_[log_var(target_cs_filter_eig1_0_5_test[:,:]),\\\n",
    "                                                log_var(target_cs_filter_eig2_0_5_test[:,:]),\\\n",
    "                                                log_var(target_ct_filter_eig1_0_5_test),\\\n",
    "                                                log_var(target_ct_filter_eig2_0_5_test),\\\n",
    "                                                \n",
    "                                                log_var(target_cs_filter_eig1_5_10_test[:,:]),\\\n",
    "                                                log_var(target_cs_filter_eig2_5_10_test[:,:]),\\\n",
    "                                                log_var(target_ct_filter_eig1_5_10_test),\\\n",
    "                                                log_var(target_ct_filter_eig2_5_10_test),\\\n",
    "                                                \n",
    "                                                log_var(target_cs_filter_eig1_10_15_test[:,:]),\\\n",
    "                                                log_var(target_cs_filter_eig2_10_15_test[:,:]),\\\n",
    "                                                log_var(target_ct_filter_eig1_10_15_test),\\\n",
    "                                                log_var(target_ct_filter_eig2_10_15_test)]\n",
    "                                                \n",
    "\n",
    "    standard_feature_test=c_[log_var(standard_cs_filter_eig1_0_5_test[:,:]),\\\n",
    "                                                log_var(standard_cs_filter_eig2_0_5_test[:,:]),\\\n",
    "                                                log_var(standard_ct_filter_eig1_0_5_test),\\\n",
    "                                                log_var(standard_ct_filter_eig2_0_5_test),\\\n",
    "                                                \n",
    "                                                log_var(standard_cs_filter_eig1_5_10_test[:,:]),\\\n",
    "                                                log_var(standard_cs_filter_eig2_5_10_test[:,:]),\\\n",
    "                                                log_var(standard_ct_filter_eig1_5_10_test),\\\n",
    "                                                log_var(standard_ct_filter_eig2_5_10_test),\\\n",
    "                                                \n",
    "                                                log_var(standard_cs_filter_eig1_10_15_test[:,:]),\\\n",
    "                                                log_var(standard_cs_filter_eig2_10_15_test[:,:]),\\\n",
    "                                                log_var(standard_ct_filter_eig1_10_15_test),\\\n",
    "                                                log_var(standard_ct_filter_eig2_10_15_test)]\n",
    "                                                \n",
    "\n",
    "    \n",
    "    label_test_eig=r_[ones([shape(target_feature_test)[0],1]),zeros([shape(standard_feature_test)[0],1])]\n",
    "    X_test_eig=r_[target_feature_test,standard_feature_test]\n",
    "    \n",
    "    # --------------------------------------------------classification testing session-------------------------------------\n",
    "    # lda\n",
    "    out_test_lda=lda_predict(X_test_eig,label_test_eig,w_lda,w_lda0)\n",
    "    TP_lda, FP_lda, TN_lda, FN_lda, P_lda, N_lda=confusion_matrix(out_test_lda,round(num_t*(1-percent)))\n",
    "    target_AC_lda_test.append(TP_lda/(TP_lda+FN_lda))\n",
    "    standard_AC_lda_test.append(TN_lda/(TN_lda+FP_lda))\n",
    "    BA_lda_test.append((target_AC_lda_test[i]+standard_AC_lda_test[i])/2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # SVM\n",
    "    out_test_svm=svm_model.predict(X_test_eig)\n",
    "    TP_svm, FP_svm, TN_svm, FN_svm, P_svm, N_svm=confusion_matrix(out_test_svm,round(num_t*(1-percent)))\n",
    "    target_AC_svm_test.append(TP_svm/(TP_svm+FN_svm))\n",
    "    standard_AC_svm_test.append(TN_svm/(TN_svm+FP_svm))\n",
    "    BA_svm_test.append((target_AC_svm_test[i]+standard_AC_svm_test[i])/2)\n",
    "\n",
    "\n",
    "    # lda bayes\n",
    "    x_lda_out_test=lda_out(w_lda, X_test_eig)\n",
    "    out_test_bayes=bayes_predict(x_lda_out_test, label_test_eig, x_lda_out,label_train_eig,pstar_lda)\n",
    "    TP_bayes, FP_bayes, TN_bayes, FN_bayes, P_bayes, N_bayes=confusion_matrix(out_test_bayes,round(num_t*(1-percent)))\n",
    "    target_AC_bayes_test.append(TP_bayes/(TP_bayes+FN_bayes))\n",
    "    standard_AC_bayes_test.append(TN_bayes/(TN_bayes+FP_bayes))\n",
    "    BA_bayes_test.append((target_AC_bayes_test[i]+standard_AC_bayes_test[i])/2)\n",
    "    print 'dataset:', i+1\n",
    "print mean(BA_lda_test), mean(BA_svm_test), mean(BA_bayes_test)\n",
    "print 'downsampling',downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7280701754385965,\n",
       " 0.6657894736842105,\n",
       " 0.8245614035087719,\n",
       " 0.5228070175438597,\n",
       " 0.7684210526315789,\n",
       " 0.6736842105263158,\n",
       " 0.6684210526315789,\n",
       " 0.5719298245614035,\n",
       " 0.5964912280701755]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BA_svm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.758096790523 0.681393807325 0.953895882878\n",
      "67.3272727273 65.8454545455 67.3909090909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\matplotlib\\font_manager.py:1282: UserWarning: findfont: Font family [u'normal'] not found. Falling back to Bitstream Vera Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    }
   ],
   "source": [
    "# plot different undersampling rates on negative class\n",
    "x=[ .05 ,.1,.2, .3 , .4, .5, .6, .7, .8, .9, 1.]\n",
    "lda_BA=array([.661,.663,.668,.667,.672,.674,.676,.679,.677,.685, .684])*100 # (m1+m2)/2\n",
    "svm_BA=array([.643,.652,.656,.666,.653,.661,.661,.660,.659,.664, .668])*100\n",
    "bayes_BA=array([.656,.657,.675,.675,.669,.672,.678,.684,.680,.680, .687])*100 # bayes threshould\n",
    "proportion=arange(1,19,19./11)\n",
    "# .05 ,.1,\n",
    "# .661,.663,\n",
    "# .643,.652,\n",
    "# .656,.657,\n",
    "# x=[.05 ,.1, .2, .3 , .4, .5, .6, .7, .8, .9, 1.]\n",
    "# lda=array([.679,.683,.694,.697,.698,.691,.688,.700,.700,.696, .696])*100 # (m1+m2)/2\n",
    "# svm=array([.664,.683,.694,.687,.684,.671,.676,.686,.686,.681, .679])*100\n",
    "# bayes=array([.682,.684,.690,.692,.691,.694,.692,.692,.693,.694, .702])*100 # bayes threshould\n",
    "# proportion=arange(1,19,19./11)\n",
    "\n",
    "\n",
    "figure()\n",
    "# plot(x,linear)\n",
    "\n",
    "plot(x,lda_BA)\n",
    "plot(x,svm_BA)\n",
    "plot(x,bayes_BA)\n",
    "legend(['LDA','WSVM','LDA-Bayes'], loc=4, borderaxespad=0.)\n",
    "xticks(arange(min(x), max(x)+1, .1))\n",
    "xlim([.05,1])\n",
    "xlabel('Downsampling rate for negative class in training session',fontsize=14,weight='bold')\n",
    "ylabel('Balanced accuracy (%)',fontsize=14,weight='bold')\n",
    "title('Balanced accuracy with varying base rate',fontsize=15,weight='bold')\n",
    "print std(lda_BA), std(svm_BA), std(bayes_BA)\n",
    "print mean(lda_BA), mean(svm_BA), mean(bayes_BA)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.721929824561 0.701929824561 0.722105263158\n",
      "0.637280701754 0.627631578947 0.64298245614\n",
      "0.684307992203 0.668908382066 0.68693957115\n"
     ]
    }
   ],
   "source": [
    "print mean(BA_lda_test[0:5]),mean(BA_svm_test[0:5]),mean(BA_bayes_test[0:5])\n",
    "print mean(BA_lda_test[5:]),mean(BA_svm_test[5:]),mean(BA_bayes_test[5:])\n",
    "print mean(BA_lda_test),mean(BA_svm_test), mean(BA_bayes_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA threshold selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excuting dataset 1 .............\n",
      "excuting dataset 2 .............\n",
      "excuting dataset 3 .............\n",
      "excuting dataset 4 .............\n",
      "excuting dataset 5 .............\n",
      "excuting dataset 6 .............\n",
      "excuting dataset 7 .............\n",
      "excuting dataset 8 .............\n",
      "excuting dataset 9 .............\n",
      "[  0.81268326   5.31306382  15.39678131   3.68351433  11.11165384\n",
      "   9.25112052  10.92627889  -1.40383539   2.26680628]\n",
      "[  0.01546827   3.62598777  12.4360933    2.69020231   9.03835874\n",
      "   7.97439777   9.57508327  -1.83628976   1.58996405]\n",
      "[ 0.71526946  1.1876712   1.56484997  1.08973347  1.4296488   1.14550783\n",
      "  1.44559532  0.37104813  0.59979033]\n",
      "[ 0.80031345  1.22112292  1.69164961  0.93141824  1.33326969  1.07501279\n",
      "  1.05664964  0.43252228  0.53099867]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:37: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\villa_000\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:38: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# observe mean and std in LDA projected space in training dataset\n",
    "lda_project_t_mu=[]\n",
    "lda_project_t_std=[]\n",
    "lda_project_s_mu=[]\n",
    "lda_project_s_std=[]\n",
    "for i in range(0,len(data_sub)):\n",
    "    variable,chan=shape(load_epoch(data_path[0],'epoch_target'))[1], 32\n",
    "    dataset=data_sub[i]\n",
    "    percent=.9  # training rate\n",
    "    test_percent=1-percent\n",
    "    portion=.99\n",
    "    \n",
    "    epoch_target_dataset=[]\n",
    "    epoch_standard_dataset=[]\n",
    "    epoch_target=zeros([1,variable,chan])\n",
    "    epoch_standard=zeros([1,variable,chan])\n",
    "    for j in range(0,len(dataset)):\n",
    "        epoch_target_dataset.append(load_epoch(dataset[j],'epoch_target'))\n",
    "        epoch_standard_dataset.append(load_epoch(dataset[j],'epoch_standard')) # chan variable obs\n",
    "        epoch_target_32,epoch_standard_32=epoch_target_dataset[j], epoch_standard_dataset[j]\n",
    "        epoch_target_6,epoch_standard_6=epoch_target_32[:,:,:],\\\n",
    "                                        epoch_standard_32[:,:,:]\n",
    "#         epoch_target_6,epoch_standard_6=epoch_target_32[array([2,24,13,14,19,17,16,18])-1,:,:],\\\n",
    "#                                         epoch_standard_32[array([2,24,13,14,19,17,16,18])-1,:,:]\n",
    "        epoch_target_6,epoch_standard_6=epoch_target_6.T, epoch_standard_6.T    # obs variable chan\n",
    "        epoch_target=r_[epoch_target, epoch_target_6]\n",
    "        epoch_standard=r_[epoch_standard, epoch_standard_6]\n",
    "        epoch_target=epoch_target[1:,:,:]    \n",
    "        epoch_standard=epoch_standard[1:,:,:]\n",
    "    flag=shape(epoch_target)[0]+shape(epoch_standard)[0] # total number of epochs\n",
    "    num_t=shape(epoch_target)[0] # number of target\n",
    "    num_s=shape(epoch_standard)[0] # number of standard\n",
    "    epoch_all= r_[epoch_target,epoch_standard]\n",
    "    \n",
    "    \n",
    "    \n",
    "    lda_project_array=lda_project[i]\n",
    "    lda_project_t=lda_project_array[0:num_t*percent]\n",
    "    lda_project_s=lda_project_array[num_t*percent:]\n",
    "    lda_project_t_mu.append(mean(lda_project_t))\n",
    "    lda_project_t_std.append(std(lda_project_t))\n",
    "    lda_project_s_mu.append(mean(lda_project_s))\n",
    "    lda_project_s_std.append(std(lda_project_s))\n",
    "    print 'excuting dataset',i+1,'.............'\n",
    "    \n",
    "print array(lda_project_t_mu)\n",
    "print array(lda_project_s_mu)\n",
    "print array(lda_project_t_std)\n",
    "print array(lda_project_s_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.36097790157\n",
      "0.121077358315\n"
     ]
    }
   ],
   "source": [
    "print mean(array(lda_project_t_mu)-\n",
    "           array(lda_project_s_mu))\n",
    "print mean(abs(array(lda_project_t_std)-array(lda_project_s_std)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7d5d9c88>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist((array(lda_project_t_std)-array(lda_project_s_std))/(array(lda_project_t_mu)-array(lda_project_s_mu)),bins=3)\n",
    "ylabel('Number',fontweight='bold')\n",
    "xlabel('Difference of standard deviation',fontweight='bold')\n",
    "title('Normalized difference of standard deviation in two conditions',fontweight='bold',fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot CSTP features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mne.io import RawArray\n",
    "from mne.channels import read_montage\n",
    "from mne.epochs import concatenate_epochs\n",
    "from mne import create_info, find_events, Epochs\n",
    "from mne.viz.topomap import _prepare_topo_plot, plot_topomap\n",
    "from mne.decoding import CSP\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import cross_val_score, LeaveOneLabelOut\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch\n",
    "from mne import pick_types\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "epochs_tot = []\n",
    "# os.chdir('/Users/Villa/Desktop/1k@5Hz_Expert_user5/EEG_recordings')\n",
    "os.chdir('D:\\\\data\\\\eeg_data\\\\eva_EEG\\\\1k@5Hz_Expert_user5\\\\EEG_recordings')\n",
    "montage=read_montage('standard_1020')\n",
    "data=mne.io.read_raw_brainvision('1_figure.vhdr', preload=True,montage=montage)\n",
    "picks = pick_types(data.info,eeg=True)\n",
    "events=find_events(data)\n",
    "data.filter(1, 20, picks=picks, filter_length='10s', l_trans_bandwidth=0.5, h_trans_bandwidth=0.5, n_jobs=1, method='fft', iir_params=None, verbose=None)\n",
    "epoch_target=Epochs(data, events, [2],-1, 2, proj=False,\n",
    "                    picks=picks, baseline=None, preload=True,\n",
    "                    add_eeg_ref=False, verbose =False)\n",
    "epoch_target.resample(250)\n",
    "\n",
    "\n",
    "epoch_standard=Epochs(data, events, [1],-1, 2, proj=False,\n",
    "                    picks=picks, baseline=None, preload=True,\n",
    "                    add_eeg_ref=False, verbose =False)\n",
    "epoch_standard.resample(250)\n",
    "\n",
    "\n",
    "\n",
    "epochs_tot.append(epoch_target)\n",
    "epochs_tot.append(epoch_standard)\n",
    "epochs = concatenate_epochs(epochs_tot)\n",
    "_,epos,_,_,_  = _prepare_topo_plot(epochs,'eeg',None)\n",
    "y.extend([1]*len(epoch_target))\n",
    "y.extend([0]*len(epoch_standard))\n",
    "X = epochs.get_data()\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "variable,chan=shape(load_epoch(data_path[0],'epoch_target'))[1], 32\n",
    "dataset=data_sub[0]\n",
    "percent=.9  # training rate\n",
    "test_percent=1-percent\n",
    "portion=.99\n",
    "\n",
    "epoch_target_dataset=[]\n",
    "epoch_standard_dataset=[]\n",
    "epoch_target=zeros([1,variable,chan])\n",
    "epoch_standard=zeros([1,variable,chan])\n",
    "for j in range(0,len(dataset)):\n",
    "    epoch_target_dataset.append(load_epoch(dataset[j],'epoch_target'))\n",
    "    epoch_standard_dataset.append(load_epoch(dataset[j],'epoch_standard')) # chan variable obs\n",
    "    epoch_target_32,epoch_standard_32=epoch_target_dataset[j], epoch_standard_dataset[j]\n",
    "    epoch_target_6,epoch_standard_6=epoch_target_32[:,:,:],\\\n",
    "                                    epoch_standard_32[:,:,:]\n",
    "#         epoch_target_6,epoch_standard_6=epoch_target_32[array([2,24,13,14,19,17,16,18])-1,:,:],\\\n",
    "#                                         epoch_standard_32[array([2,24,13,14,19,17,16,18])-1,:,:]\n",
    "    epoch_target_6,epoch_standard_6=epoch_target_6.T, epoch_standard_6.T    # obs variable chan\n",
    "    epoch_target=r_[epoch_target, epoch_target_6]\n",
    "    epoch_standard=r_[epoch_standard, epoch_standard_6]\n",
    "    epoch_target=epoch_target[1:,:,:]    \n",
    "    epoch_standard=epoch_standard[1:,:,:]\n",
    "\n",
    "flag=shape(epoch_target)[0]+shape(epoch_standard)[0] # total number of epochs\n",
    "num_t=shape(epoch_target)[0] # number of target\n",
    "num_s=shape(epoch_standard)[0] # number of standard\n",
    "epoch_all= r_[epoch_target,epoch_standard]\n",
    "#     epoch_all   # r_[target, standard]\n",
    "\n",
    "#   ----------------------------------------------filter-------------------------------------\n",
    "#   0-5Hz  \n",
    "epoch_all_0_5=zeros_like(epoch_all)\n",
    "for j in range(0,chan):\n",
    "    epoch_all_0_5[:,:,j]=butter_bandpass_filter(epoch_all[:,:,j], .1, 5, 250, order=3)\n",
    "\n",
    "\n",
    "#   5-10Hz  \n",
    "epoch_all_5_10=zeros_like(epoch_all)\n",
    "for j in range(0,chan):\n",
    "    epoch_all_5_10[:,:,j]=butter_bandpass_filter(epoch_all[:,:,j], 5, 10, 250, order=3)   \n",
    "\n",
    "#   10-15Hz  \n",
    "epoch_all_10_15=zeros_like(epoch_all)\n",
    "for j in range(0,chan):\n",
    "    epoch_all_10_15[:,:,j]=butter_bandpass_filter(epoch_all[:,:,j], 10, 15, 250, order=3)    \n",
    "\n",
    "# #   15-20Hz  \n",
    "#     epoch_all_15_20=zeros_like(epoch_all)\n",
    "#     for j in range(0,chan):\n",
    "#         epoch_all_15_20[:,:,j]=butter_bandpass_filter(epoch_all[:,:,j], 15, 20, 250, order=3)\n",
    "\n",
    "#   --------------------------------------------construct sub band training and testing epochs for CSTP--------------------------------\n",
    "# 0-5Hz\n",
    "epoch_target_train_0_5, epoch_target_test_0_5=cross_validation.train_test_split(epoch_all_0_5[0:num_t,:,:], train_size=percent,random_state=42)\n",
    "epoch_standard_train_0_5, epoch_standard_test_0_5=cross_validation.train_test_split(epoch_all_0_5[num_t:,:,:], train_size=percent,random_state=42)\n",
    "epoch_train_0_5=r_[epoch_target_train_0_5,epoch_standard_train_0_5]\n",
    "label_train=r_[ones(shape(epoch_target_train_0_5)[0]),zeros(shape(epoch_standard_train_0_5)[0])]\n",
    "epoch_test_0_5=r_[epoch_target_test_0_5,epoch_standard_test_0_5]\n",
    "label_test=r_[ones(shape(epoch_target_test_0_5)[0]),zeros(shape(epoch_standard_test_0_5)[0])]\n",
    "\n",
    "# 5-10Hz\n",
    "epoch_target_train_5_10, epoch_target_test_5_10=cross_validation.train_test_split(epoch_all_5_10[0:num_t,:,:], train_size=percent,random_state=42)\n",
    "epoch_standard_train_5_10, epoch_standard_test_5_10=cross_validation.train_test_split(epoch_all_5_10[num_t:,:,:], train_size=percent,random_state=42)\n",
    "epoch_train_5_10=r_[epoch_target_train_5_10,epoch_standard_train_5_10]\n",
    "epoch_test_5_10=r_[epoch_target_test_5_10,epoch_standard_test_5_10]\n",
    "\n",
    "# 10-15Hz\n",
    "epoch_target_train_10_15, epoch_target_test_10_15=cross_validation.train_test_split(epoch_all_10_15[0:num_t,:,:], train_size=percent,random_state=42)\n",
    "epoch_standard_train_10_15, epoch_standard_test_10_15=cross_validation.train_test_split(epoch_all_10_15[num_t:,:,:], train_size=percent,random_state=42)\n",
    "epoch_train_10_15=r_[epoch_target_train_10_15,epoch_standard_train_10_15]\n",
    "epoch_test_10_15=r_[epoch_target_test_10_15,epoch_standard_test_10_15]\n",
    "\n",
    "#     # 15-20Hz\n",
    "#     epoch_target_train_15_20, epoch_target_test_15_20=cross_validation.train_test_split(epoch_all_15_20[0:num_t,:,:], train_size=percent,random_state=42)\n",
    "#     epoch_standard_train_15_20, epoch_standard_test_15_20=cross_validation.train_test_split(epoch_all_15_20[num_t:,:,:], train_size=percent,random_state=42)\n",
    "#     epoch_train_15_20=r_[epoch_target_train_15_20,epoch_standard_train_15_20]\n",
    "#     epoch_test_15_20=r_[epoch_target_test_15_20,epoch_standard_test_15_20]\n",
    "\n",
    "\n",
    "# ---------------------------------------------CSTP calculation----------------------------------------\n",
    "# train 300-500\n",
    "downsampling=5\n",
    "# 0-5Hz\n",
    "cs_pattern_0_5,cs_filter_0_5=myCSP(epoch_train_0_5[:,300:500,:],label_train)\n",
    "ct_pattern_0_5, ct_filter_0_5=myCTP(epoch_train_0_5[:,300:500,:],label_train,downsampling)\n",
    "\n",
    "ind_eig_cs1_0_5=max_target_lamba_ind(epoch_train_0_5[0:num_t*percent,300:500,:],epoch_train_0_5[num_t*percent:,300:500,:],cs_pattern_0_5,cs_filter_0_5)\n",
    "ind_eig_ct1_0_5=max_target_lamba_ind(transpose(epoch_train_0_5[0:num_t*percent,300:500:downsampling,:],(0,2,1)),\\\n",
    "                              transpose(epoch_train_0_5[num_t*percent:,300:500:downsampling,:],(0,2,1)),ct_pattern_0_5,ct_filter_0_5)\n",
    "\n",
    "ind_eig_cs2_0_5=max_target_lamba_ind(epoch_train_0_5[num_t*percent:,300:500,:],epoch_train_0_5[0:num_t*percent,300:500,:],cs_pattern_0_5,cs_filter_0_5)\n",
    "ind_eig_ct2_0_5=max_target_lamba_ind(transpose(epoch_train_0_5[num_t*percent:,300:500:downsampling,:],(0,2,1)),\\\n",
    "                              transpose(epoch_train_0_5[0:num_t*percent,300:500:downsampling,:],(0,2,1)),ct_pattern_0_5,ct_filter_0_5)\n",
    "\n",
    "\n",
    "# 5-10Hz\n",
    "cs_pattern_5_10,cs_filter_5_10=myCSP(epoch_train_5_10[:,300:500,:],label_train)\n",
    "ct_pattern_5_10, ct_filter_5_10=myCTP(epoch_train_5_10[:,300:500,:],label_train,downsampling)\n",
    "\n",
    "ind_eig_cs1_5_10=max_target_lamba_ind\\\n",
    "                (epoch_train_5_10[0:num_t*percent,300:500,:],epoch_train_5_10[num_t*percent:,300:500,:],cs_pattern_5_10,cs_filter_5_10)\n",
    "ind_eig_ct1_5_10=max_target_lamba_ind(transpose(epoch_train_5_10[0:num_t*percent,300:500:downsampling,:],(0,2,1)),\\\n",
    "                              transpose(epoch_train_5_10[num_t*percent:,300:500:downsampling,:],(0,2,1)),ct_pattern_5_10,ct_filter_5_10)\n",
    "\n",
    "ind_eig_cs2_5_10=max_target_lamba_ind\\\n",
    "                (epoch_train_5_10[num_t*percent:,300:500,:],epoch_train_5_10[0:num_t*percent,300:500,:],cs_pattern_5_10,cs_filter_5_10)\n",
    "ind_eig_ct2_5_10=max_target_lamba_ind(transpose(epoch_train_5_10[num_t*percent:,300:500:downsampling,:],(0,2,1)),\\\n",
    "                              transpose(epoch_train_5_10[0:num_t*percent,300:500:downsampling,:],(0,2,1)),ct_pattern_5_10,ct_filter_5_10)\n",
    "\n",
    "\n",
    "# 10-15Hz\n",
    "cs_pattern_10_15,cs_filter_10_15=myCSP(epoch_train_10_15[:,300:500,:],label_train)\n",
    "ct_pattern_10_15, ct_filter_10_15=myCTP(epoch_train_10_15[:,300:500,:],label_train,downsampling)\n",
    "\n",
    "ind_eig_cs1_10_15=max_target_lamba_ind\\\n",
    "                  (epoch_train_10_15[0:num_t*percent,300:500,:],epoch_train_10_15[num_t*percent:,300:500,:],cs_pattern_10_15,cs_filter_10_15)\n",
    "ind_eig_ct1_10_15=max_target_lamba_ind(transpose(epoch_train_10_15[0:num_t*percent,300:500:downsampling,:],(0,2,1)),\\\n",
    "                              transpose(epoch_train_10_15[num_t*percent:,300:500:downsampling,:],(0,2,1)),ct_pattern_10_15,ct_filter_10_15)\n",
    "\n",
    "ind_eig_cs2_10_15=max_target_lamba_ind\\\n",
    "                 (epoch_train_10_15[num_t*percent:,300:500,:],epoch_train_10_15[0:num_t*percent,300:500,:],cs_pattern_10_15,cs_filter_10_15)\n",
    "ind_eig_ct2_10_15=max_target_lamba_ind(transpose(epoch_train_10_15[num_t*percent:,300:500:downsampling,:],(0,2,1)),\\\n",
    "                              transpose(epoch_train_10_15[0:num_t*percent,300:500:downsampling,:],(0,2,1)),ct_pattern_10_15,ct_filter_10_15)\n",
    "\n",
    "\n",
    "# -------------------------------------------CSTP training feature selection-----------------------------------\n",
    "# CSP feature\n",
    "# 0-5Hz\n",
    "cs_filter_para_eig1_0_5=cs_filter_0_5[ind_eig_cs1_0_5,:]\n",
    "cs_filter_para_eig2_0_5=cs_filter_0_5[ind_eig_cs2_0_5,:]\n",
    "epoch_cs_filter_eig1_0_5=signal_projection(cs_filter_para_eig1_0_5, epoch_train_0_5[:,300:500,:])\n",
    "epoch_cs_filter_eig2_0_5=signal_projection(cs_filter_para_eig2_0_5, epoch_train_0_5[:,300:500,:])\n",
    "target_cs_filter_eig1_0_5,target_cs_filter_eig2_0_5=epoch_cs_filter_eig1_0_5[0:num_t*percent,:], epoch_cs_filter_eig2_0_5[0:num_t*percent,:]\n",
    "standard_cs_filter_eig1_0_5,standard_cs_filter_eig2_0_5=epoch_cs_filter_eig1_0_5[num_t*percent:,:], epoch_cs_filter_eig2_0_5[num_t*percent:,:]\n",
    "\n",
    "# 5-10Hz\n",
    "cs_filter_para_eig1_5_10=cs_filter_5_10[ind_eig_cs1_5_10,:]\n",
    "cs_filter_para_eig2_5_10=cs_filter_5_10[ind_eig_cs2_5_10,:]\n",
    "epoch_cs_filter_eig1_5_10=signal_projection(cs_filter_para_eig1_5_10, epoch_train_5_10[:,300:500,:])\n",
    "epoch_cs_filter_eig2_5_10=signal_projection(cs_filter_para_eig2_5_10, epoch_train_5_10[:,300:500,:])\n",
    "target_cs_filter_eig1_5_10,target_cs_filter_eig2_5_10=epoch_cs_filter_eig1_5_10[0:num_t*percent,:], epoch_cs_filter_eig2_5_10[0:num_t*percent,:]\n",
    "standard_cs_filter_eig1_5_10,standard_cs_filter_eig2_5_10=epoch_cs_filter_eig1_5_10[num_t*percent:,:], epoch_cs_filter_eig2_5_10[num_t*percent:,:]\n",
    "\n",
    "# 10-15Hz\n",
    "cs_filter_para_eig1_10_15=cs_filter_10_15[ind_eig_cs1_10_15,:]\n",
    "cs_filter_para_eig2_10_15=cs_filter_10_15[ind_eig_cs2_10_15,:]\n",
    "epoch_cs_filter_eig1_10_15=signal_projection(cs_filter_para_eig1_10_15, epoch_train_10_15[:,300:500,:])\n",
    "epoch_cs_filter_eig2_10_15=signal_projection(cs_filter_para_eig2_0_5, epoch_train_10_15[:,300:500,:])\n",
    "target_cs_filter_eig1_10_15,target_cs_filter_eig2_10_15=epoch_cs_filter_eig1_10_15[0:num_t*percent,:], epoch_cs_filter_eig2_10_15[0:num_t*percent,:]\n",
    "standard_cs_filter_eig1_10_15,standard_cs_filter_eig2_10_15=epoch_cs_filter_eig1_10_15[num_t*percent:,:], epoch_cs_filter_eig2_10_15[num_t*percent:,:]\n",
    "\n",
    "\n",
    "\n",
    "# CTP feature\n",
    "# 0-5Hz\n",
    "epoch_ct_filter_eig1_0_5=signal_projection(ct_filter_0_5[ind_eig_ct1_0_5,:], transpose(epoch_train_0_5[:,300:500:downsampling,:],(0,2,1)))\n",
    "epoch_ct_filter_eig2_0_5=signal_projection(ct_filter_0_5[ind_eig_ct2_0_5,:], transpose(epoch_train_0_5[:,300:500:downsampling,:],(0,2,1)))\n",
    "target_ct_filter_eig1_0_5,target_ct_filter_eig2_0_5=epoch_ct_filter_eig1_0_5[0:num_t*percent,:], epoch_ct_filter_eig2_0_5[0:num_t*percent,:]\n",
    "standard_ct_filter_eig1_0_5,standard_ct_filter_eig2_0_5=epoch_ct_filter_eig1_0_5[num_t*percent:,:], epoch_ct_filter_eig2_0_5[num_t*percent:,:]\n",
    "\n",
    "\n",
    "# 5-10Hz\n",
    "epoch_ct_filter_eig1_5_10=signal_projection(ct_filter_5_10[ind_eig_ct1_5_10,:], transpose(epoch_train_5_10[:,300:500:downsampling,:],(0,2,1)))\n",
    "epoch_ct_filter_eig2_5_10=signal_projection(ct_filter_5_10[ind_eig_ct2_5_10,:], transpose(epoch_train_5_10[:,300:500:downsampling,:],(0,2,1)))\n",
    "target_ct_filter_eig1_5_10,target_ct_filter_eig2_5_10=epoch_ct_filter_eig1_5_10[0:num_t*percent,:], epoch_ct_filter_eig2_5_10[0:num_t*percent,:]\n",
    "standard_ct_filter_eig1_5_10,standard_ct_filter_eig2_5_10=epoch_ct_filter_eig1_5_10[num_t*percent:,:], epoch_ct_filter_eig2_5_10[num_t*percent:,:]\n",
    "\n",
    "\n",
    "# 10-15Hz\n",
    "epoch_ct_filter_eig1_10_15=signal_projection(ct_filter_10_15[ind_eig_ct1_10_15,:], transpose(epoch_train_10_15[:,300:500:downsampling,:],(0,2,1)))\n",
    "epoch_ct_filter_eig2_10_15=signal_projection(ct_filter_10_15[ind_eig_ct2_10_15,:], transpose(epoch_train_10_15[:,300:500:downsampling,:],(0,2,1)))\n",
    "target_ct_filter_eig1_10_15,target_ct_filter_eig2_10_15=epoch_ct_filter_eig1_10_15[0:num_t*percent,:], epoch_ct_filter_eig2_10_15[0:num_t*percent,:]\n",
    "standard_ct_filter_eig1_10_15,standard_ct_filter_eig2_10_15=epoch_ct_filter_eig1_10_15[num_t*percent:,:], epoch_ct_filter_eig2_10_15[num_t*percent:,:]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot spatial filtered signal and temporal pattern\n",
    "figure()\n",
    "subplot(2,2,1)\n",
    "ts=arange(200,1000,4)\n",
    "plot(ts,mean(target_cs_filter_eig1_0_5,axis=0))\n",
    "xlabel('Time (ms)',fontweight='bold')\n",
    "title('Target features')\n",
    "title('Filtered target temporal features',fontweight='bold',fontsize=25)\n",
    "\n",
    "subplot(2,2,3)\n",
    "plot(ts,mean(target_cs_filter_eig2_0_5,axis=0))\n",
    "xlabel('Time (ms)',fontweight='bold')\n",
    "# title('Filtered target temporal features by standard condition spatial filter',fontweight='bold',fontsize=21)\n",
    "\n",
    "subplot(2,2,2)\n",
    "plot(ts,mean(standard_cs_filter_eig1_0_5,axis=0))\n",
    "xlabel('Time (ms)',fontweight='bold')\n",
    "title('Standard features')\n",
    "title('Filtered standard temporal features',fontweight='bold',fontsize=25)\n",
    "\n",
    "subplot(2,2,4)\n",
    "plot(ts,mean(standard_cs_filter_eig2_0_5,axis=0))\n",
    "xlabel('Time (ms)',fontweight='bold')\n",
    "# title('Filtered standard temporal features by standard condition spatial filter',fontweight='bold',fontsize=21)\n",
    "\n",
    "\n",
    "\n",
    "fig,ax_topo = subplots(1,1)\n",
    "img, _ = plot_topomap(mean(target_ct_filter_eig1_0_5,axis=0),epos)\n",
    "divider = make_axes_locatable(ax_topo)\n",
    "ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "colorbar(img, cax=ax_colorbar)\n",
    "# suptitle('Filtered target spatial features by temporal filter 1',fontweight='bold',fontsize=21)\n",
    "\n",
    "\n",
    "fig,ax_topo = subplots(1, 1)\n",
    "img, _ = plot_topomap(-mean(target_ct_filter_eig2_0_5,axis=0),epos)\n",
    "divider = make_axes_locatable(ax_topo)\n",
    "ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "colorbar(img, cax=ax_colorbar)\n",
    "# suptitle('Filtered target spatial features by temporal filter 2',fontweight='bold',fontsize=21)\n",
    "\n",
    "\n",
    "fig,ax_topo = subplots(1, 1)\n",
    "img, _ = plot_topomap(mean(standard_ct_filter_eig1_0_5,axis=0),epos)\n",
    "divider = make_axes_locatable(ax_topo)\n",
    "ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "colorbar(img, cax=ax_colorbar)\n",
    "# suptitle('Filtered standard spatial features by temporal filter 1',fontweight='bold',fontsize=21)\n",
    "\n",
    "\n",
    "fig,ax_topo = subplots(1, 1)\n",
    "img, _ = plot_topomap(-mean(standard_ct_filter_eig2_0_5,axis=0),epos)\n",
    "divider = make_axes_locatable(ax_topo)\n",
    "ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "colorbar(img, cax=ax_colorbar)\n",
    "# suptitle('Filtered standard spatial features by temporal filter 2',fontweight='bold',fontsize=21)\n",
    "\n",
    "\n",
    "# figure()\n",
    "# subplot(2,1,1)\n",
    "# ts=arange(200,1000,4)\n",
    "# plot(ts,-mean(target_cs_filter_eig1,axis=0),'r',linewidth=2)\n",
    "# plot(ts,mean(standard_cs_filter_eig1,axis=0),'b',linewidth=2)\n",
    "# legend(['Target', 'Standard'])\n",
    "# xlabel('Time (ms)')\n",
    "# title('Spatial filtered signals')\n",
    "\n",
    "# # subplot(2,1,2)\n",
    "# # tt=arange(200,1000,20)\n",
    "# # plot(tt,ct_pattern[:,ind_eig_ct1],'r',linewidth=2)\n",
    "# # plot(tt,ct_pattern[:,ind_eig_ct2],'b',linewidth=2)\n",
    "# # legend(['Target', 'Standard'])\n",
    "# # xlabel('Time (ms)')\n",
    "# # title('Common temporal patterns')\n",
    "\n",
    "\n",
    "# figure()\n",
    "# ts=arange(200,1000,4)\n",
    "# plot(ts,-mean(target_cs_filter_eig1,axis=0),'r',linewidth=2)\n",
    "# plot(ts,mean(epoch_filter[0:num_t,300:500,13],axis=0),'b',linewidth=2)\n",
    "# legend(['Spatial filtered target condition', 'Non-spatial filtered target condition'])\n",
    "# xlabel('Time (ms)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot spatial filtered signal and temporal pattern\n",
    "figure()\n",
    "\n",
    "subplot(2,2,1)\n",
    "ts=arange(200,1000,4)\n",
    "plot(ts,mean(target_cs_filter_eig1_5_10,axis=0))\n",
    "xlabel('Time (ms)',fontweight='bold')\n",
    "title('Target features')\n",
    "title('Filtered target temporal features',fontweight='bold',fontsize=25)\n",
    "\n",
    "subplot(2,2,3)\n",
    "plot(ts,mean(target_cs_filter_eig2_5_10,axis=0))\n",
    "xlabel('Time (ms)',fontweight='bold')\n",
    "# title('Filtered target temporal features by standard condition spatial filter',fontweight='bold',fontsize=21)\n",
    "\n",
    "subplot(2,2,2)\n",
    "plot(ts,mean(standard_cs_filter_eig1_5_10,axis=0))\n",
    "xlabel('Time (ms)',fontweight='bold')\n",
    "title('Standard features')\n",
    "title('Filtered standard temporal features',fontweight='bold',fontsize=25)\n",
    "\n",
    "subplot(2,2,4)\n",
    "plot(ts,mean(standard_cs_filter_eig2_5_10,axis=0))\n",
    "xlabel('Time (ms)',fontweight='bold')\n",
    "# title('Filtered standard temporal features by standard condition spatial filter',fontweight='bold',fontsize=21)\n",
    "\n",
    "\n",
    "\n",
    "fig,ax_topo = subplots(1,1)\n",
    "img, _ = plot_topomap(-mean(target_ct_filter_eig1_5_10,axis=0),epos)\n",
    "divider = make_axes_locatable(ax_topo)\n",
    "ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "colorbar(img, cax=ax_colorbar)\n",
    "# suptitle('Filtered target spatial features by temporal filter 1',fontweight='bold',fontsize=21)\n",
    "\n",
    "\n",
    "fig,ax_topo = subplots(1, 1)\n",
    "img, _ = plot_topomap(-mean(target_ct_filter_eig2_5_10,axis=0),epos)\n",
    "divider = make_axes_locatable(ax_topo)\n",
    "ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "colorbar(img, cax=ax_colorbar)\n",
    "# suptitle('Filtered target spatial features by temporal filter 2',fontweight='bold',fontsize=21)\n",
    "\n",
    "\n",
    "fig,ax_topo = subplots(1, 1)\n",
    "img, _ = plot_topomap(mean(standard_ct_filter_eig1_5_10,axis=0),epos)\n",
    "divider = make_axes_locatable(ax_topo)\n",
    "ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "colorbar(img, cax=ax_colorbar)\n",
    "# suptitle('Filtered standard spatial features by temporal filter 1',fontweight='bold',fontsize=21)\n",
    "\n",
    "\n",
    "fig,ax_topo = subplots(1, 1)\n",
    "img, _ = plot_topomap(mean(-standard_ct_filter_eig2_5_10,axis=0),epos)\n",
    "divider = make_axes_locatable(ax_topo)\n",
    "ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "colorbar(img, cax=ax_colorbar)\n",
    "# suptitle('Filtered standard spatial features by temporal filter 2',fontweight='bold',fontsize=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot spatial filtered signal and temporal pattern\n",
    "figure()\n",
    "subplot(2,2,1)\n",
    "ts=arange(200,1000,4)\n",
    "plot(ts,mean(target_cs_filter_eig1_10_15,axis=0))\n",
    "xlabel('Time (ms)',fontweight='bold')\n",
    "title('Target features')\n",
    "title('Filtered target temporal features',fontweight='bold',fontsize=25)\n",
    "\n",
    "subplot(2,2,3)\n",
    "plot(ts,mean(target_cs_filter_eig2_10_15,axis=0))\n",
    "xlabel('Time (ms)',fontweight='bold')\n",
    "# title('Filtered target temporal features by standard condition spatial filter',fontweight='bold',fontsize=21)\n",
    "\n",
    "subplot(2,2,2)\n",
    "plot(ts,mean(standard_cs_filter_eig1_10_15,axis=0))\n",
    "xlabel('Time (ms)',fontweight='bold')\n",
    "title('Standard features')\n",
    "title('Filtered standard temporal features',fontweight='bold',fontsize=25)\n",
    "\n",
    "subplot(2,2,4)\n",
    "plot(ts,mean(standard_cs_filter_eig2_10_15,axis=0))\n",
    "xlabel('Time (ms)',fontweight='bold')\n",
    "# title('Filtered standard temporal features by standard condition spatial filter',fontweight='bold',fontsize=21)\n",
    "\n",
    "\n",
    "\n",
    "fig,ax_topo = subplots(1,1)\n",
    "img, _ = plot_topomap(-mean(target_ct_filter_eig1_10_15,axis=0),epos)\n",
    "divider = make_axes_locatable(ax_topo)\n",
    "ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "colorbar(img, cax=ax_colorbar)\n",
    "# suptitle('Filtered target spatial features by temporal filter 1',fontweight='bold',fontsize=21)\n",
    "\n",
    "\n",
    "fig,ax_topo = subplots(1, 1)\n",
    "img, _ = plot_topomap(-mean(target_ct_filter_eig2_10_15,axis=0),epos)\n",
    "divider = make_axes_locatable(ax_topo)\n",
    "ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "colorbar(img, cax=ax_colorbar)\n",
    "# suptitle('Filtered target spatial features by temporal filter 2',fontweight='bold',fontsize=21)\n",
    "\n",
    "\n",
    "fig,ax_topo = subplots(1, 1)\n",
    "img, _ = plot_topomap(mean(standard_ct_filter_eig1_10_15,axis=0),epos)\n",
    "divider = make_axes_locatable(ax_topo)\n",
    "ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "colorbar(img, cax=ax_colorbar)\n",
    "# suptitle('Filtered standard spatial features by temporal filter 1',fontweight='bold',fontsize=21)\n",
    "\n",
    "\n",
    "fig,ax_topo = subplots(1, 1)\n",
    "img, _ = plot_topomap(-mean(standard_ct_filter_eig2_10_15,axis=0),epos)\n",
    "divider = make_axes_locatable(ax_topo)\n",
    "ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "colorbar(img, cax=ax_colorbar)\n",
    "# suptitle('Filtered standard spatial features by temporal filter 2',fontweight='bold',fontsize=21)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
